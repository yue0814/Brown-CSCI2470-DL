HW1: MNIST Neural Network From Scratch
====
#### Author: Yue Peng

In my first step, I initialized some hyperparameters following the instruction like batch size = 20, learning rate = 1e-4, epoch = 1. As for embedding size, I refer to the book which used 100 commonly. I set a hidden layer size as 625 and kept decreasing with a small amount until the training perplexity and development perplexity looks great with quickly execution time. Finally, the hidden layer size is 128.
